import os.path
import sys
import math
import logging

import numpy as np
import pandas as pd
from pathlib import Path
from typing import Tuple, Dict, List, Union
from job_pool import JobPool

import topas_pipeline.topas.topas

from . import config
from . import sample_annotation as sa
from . import utils as utils
from . import metrics as metrics
from . import clinical_annotation
from . import clinical_tools
from .topas import annotation as topas_annotation
from .topas import phosphorylation
from .topas import substrate_phosphorylation
from .topas import protein_phosphorylation

logger = logging.getLogger(__name__)

TOPAS_SCORE_COLUMN = clinical_tools.TOPAS_SCORE_COLUMN
TOPAS_SUBSCORE_COLUMN = clinical_tools.TOPAS_SUBSCORE_COLUMN
TOPAS_SCORE_COLUMNS = clinical_tools.TOPAS_SCORE_COLUMNS
TOPAS_SUBSCORE_COLUMNS = clinical_tools.TOPAS_SUBSCORE_COLUMNS

ANNOTATION_COLUMNS = dict()
ANNOTATION_COLUMNS["pp"] = {
    **TOPAS_SCORE_COLUMNS,
    "Site positions identified (MQ)": "Site positions (MQ identified - PSP)",
    "Site positions": "Site positions (PSP)",
    "PSP Kinases": "Kinases (PSP)",
    "PSP_ON_FUNCTION": "Effects on Modified Protein (PSP)",
    "PSP_ON_PROCESS": "Effects on Biological Processes (PSP)",
    "PSP_ON_PROT_INTERACT": "Induce Interaction with protein (PSP)",
    "PSP_ON_OTHER_INTERACT": "Induce Interaction with other (PSP)",
    "PSP_NOTES": "PSP NOTES",
    "PSP_LT_LIT": "Low throughput studies (PSP)",
    "PSP_MS_LIT": "High throughput studies (PSP)",
    "PSP_MS_CST": "CST studies (PSP)",
}
ANNOTATION_COLUMNS["fp"] = {
    **TOPAS_SCORE_COLUMNS,
}


def create_report(
    results_folder: Union[str, Path],
    debug: bool,
    report_config: config.Report,
    annot_file: Union[str, Path],
    data_types: List[str],
) -> None:
    """Creates an Excel report for each sample
    Requires that annot_{data_type}.csv is generated by clinical_annotation.py
    Requires that [phospho|full_proteome]_[z|rank|p|fc].csv files are generated by metrics.py
    # TODO: should require that kinase and phospho scoring files are generated (by proper exception handling if not)
    kinase_scores.tsv
    protein_scores.tsv
    """
    logger.info("Running report creation module")

    # TODO: add a check that batch selected exists in data and optimize this whole functionality.. rarely ever use it because it's too complicated
    if report_config.samples_for_report == "none":
        return
    if report_config.samples_for_report in ["all", "ALL", ""]:
        samples_list = []
    else:
        try:
            samples_for_report = str(report_config.samples_for_report)
        except ValueError:
            print("Input not of type int or string")
        samples_list = samples_for_report

    topas_annotation_df = topas_annotation.read_topas_annotations(annot_file)

    # Load sample annotation file
    sample_annotation_df = sa.load_sample_annotation(
        os.path.join(results_folder, "sample_annot_filtered.csv")
    )
    sample_annotation_df = sa.filter_sample_annotation(
        sample_annotation_df,
        remove_qc_failed=False,
        remove_replicates=False,
        remove_reference=True,
    )
    sample_annotation_df["Batch Name"] = (
        sample_annotation_df["Cohort"]
        + "_Batch"
        + sample_annotation_df["Batch Name"].astype(str)
    )
    sample_annotation_df = sample_annotation_df.sort_values(by="Batch Name")

    # Create a mapping of patient columns to batch names directly
    sample_to_batch_dict = dict(
        zip(
            sample_annotation_df.transpose().add_prefix("pat_").columns.tolist(),
            sample_annotation_df["Batch Name"].values.tolist(),
        )
    )

    # Read scoring files and calculate extra annotation metrics
    topas_scores, topas_subscores, kinase_scores, protein_scores = (
        read_and_compute_scores(results_folder)
    )

    # TODO: it would make a lot of sense to move these calculations to it's own module and have a report writing only module which can be reused on portal
    # Questio is HOW to make it fast and efficient (takes a lot of memory to read all the data now. Do we need to read and close one file at a time?)

    logger.info("Calculate within batch ranks")
    topas_scores["measures"] |= compute_in_batch_rank(
        topas_scores["scores"], sample_to_batch_dict
    )
    topas_subscores["measures"] |= compute_in_batch_rank(
        topas_subscores["scores"], sample_to_batch_dict
    )
    kinase_scores["measures"] |= compute_in_batch_rank(
        kinase_scores["scores"], sample_to_batch_dict
    )
    protein_scores["measures"] |= compute_in_batch_rank(
        protein_scores["scores"], sample_to_batch_dict
    )

    if len(samples_list) == 0:
        samples_for_report = topas_scores["scores"].columns.tolist()
    else:
        samples_for_report = get_samples_for_report(sample_annotation_df, samples_list)

    # Read and prepare patient intensity data + quant measures (fc, z-score)
    measure_dfs = dict()
    for data_type in data_types:
        measures = metrics.read_measures(results_folder, data_type)
        measures["occurrence"] = None
        annot_df = clinical_annotation.read_annotated_expression_file(
            results_folder, data_type
        )
        annot_df = post_process_topas_columns(annot_df)
        measure_dfs[data_type] = {"measures": measures, "scores": annot_df}
    measure_dfs["pp"]["measures"] |= compute_in_batch_rank(
        measure_dfs["pp"]["measures"]["z-score"], sample_to_batch_dict
    )

    samples_for_report.reverse()  # print reports for newest batch first
    write_patient_reports(
        results_folder,
        measure_dfs,
        topas_scores,
        topas_subscores,
        kinase_scores,
        protein_scores,
        samples_for_report,
        topas_annotation_df,
    )


def read_and_compute_scores(results_folder: Union[str, Path]) -> Tuple:
    # TODO: optimize reading and filtering of score files
    topas_scores, topas_subscores, kinase_scores, protein_scores = (
        dict(),
        dict(),
        dict(),
        dict(),
    )
    topas_scores["scores"] = topas_pipeline.topas.topas.read_topas_scores(results_folder)
    topas_subscores["scores"] = phosphorylation.read_topas_subscores(results_folder)

    kinase_scores["scores"] = substrate_phosphorylation.read_kinase_scoring(results_folder)
    kinase_scores["targets"] = kinase_scores["scores"].filter(regex=r"^targets_")
    kinase_scores["scores"] = kinase_scores["scores"].loc[
        :, ~kinase_scores["scores"].columns.str.startswith("targets_")
    ]
    kinase_scores["scores"] = kinase_scores["scores"].filter(regex="pat_")

    protein_scores["scores"] = protein_phosphorylation.read_protein_scoring(
        results_folder
    )
    protein_scores["scores"] = protein_scores["scores"].filter(regex="pat_")

    for score_dict in [topas_scores, topas_subscores, kinase_scores, protein_scores]:
        score_dict["measures"] = metrics.get_metrics(score_dict["scores"])
        score_dict["significance"] = (
            score_dict["scores"].copy().apply(assign_significance_score, axis=1)
        )
    return topas_scores, topas_subscores, kinase_scores, protein_scores


def get_unique_topas_names(topas_names: Union[List, str, float]) -> str:
    if type(topas_names) != list and type(topas_names) != float:
        topas_names = topas_names.split(";")
    if type(topas_names) != float:
        topas_names = ";".join(np.unique(np.array(topas_names)))
    return topas_names


def merge_topas_score_and_subscore_names(row: pd.Series) -> str:
    topas_score_col = TOPAS_SCORE_COLUMN
    topas_subscore_col = TOPAS_SUBSCORE_COLUMN
    topas_subscore_names = row[topas_subscore_col]
    if not pd.isnull(row[topas_subscore_col]):
        topas_subscore_list = row[topas_subscore_col].split(";")
        topas_score_list = row[topas_score_col].split(";")
        topas_subscore_names = [
            (
                topas_score_list[i] + " - " + topas_subscore_list[i]
                if len(topas_score_list[i]) > 0
                else ""
            )
            for i in range(len(topas_subscore_list))
        ]
        topas_subscore_names = get_unique_topas_names(topas_subscore_names)
    return topas_subscore_names


def post_process_topas_columns(annot_df: pd.DataFrame) -> pd.DataFrame:
    # Get unique TOPAS names and add main TOPAS name to TOPAS subscore level
    for key in TOPAS_SUBSCORE_COLUMNS.keys():
        annot_df[key] = annot_df.apply(merge_topas_score_and_subscore_names, axis=1)
    for key in TOPAS_SCORE_COLUMNS.keys():
        annot_df[key] = annot_df[key].apply(get_unique_topas_names)
    return annot_df


def compute_in_batch_rank(
    topas_scores_df: pd.DataFrame, sample_batch_dict: Dict[str, str]
) -> Dict:
    # Map each sample to its respective batch
    batch_names_by_sample = [
        sample_batch_dict[sample]
        for sample in topas_scores_df.columns.str.removeprefix("zscore_")
    ]

    batch_ranks = []
    batch_occurrences = []
    for batch in set(batch_names_by_sample):
        batch_mask = np.array(batch_names_by_sample) == batch
        batch_scores = topas_scores_df.loc[:, batch_mask]
        ranks_df = metrics.Metrics.get_rank(batch_scores)
        ranks_df.columns = ranks_df.columns.str.replace("rank_zscore_", "rank_")

        occurrences = ranks_df.pop("rank_max")
        ranks_df = ranks_df.add_prefix("batch_")
        batch_ranks.append(ranks_df)

        occurrences_df = pd.DataFrame(
            np.tile(occurrences.values, (len(ranks_df.columns), 1)).T,
            columns=ranks_df.columns.str.replace("batch_rank_", "batch_occurrence_"),
            index=ranks_df.index,
        )
        batch_occurrences.append(occurrences_df)
    return {
        "batch_rank": pd.concat(batch_ranks, axis=1),
        "batch_occurrence": pd.concat(batch_occurrences, axis=1),
    }


def get_samples_for_report(
    sample_annotation_df: pd.DataFrame, samples_for_report: Union[str, List]
):
    # samples_for_report = []
    # TODO: add test for this ? to crash with a message at least
    if "," in samples_for_report or ";" in samples_for_report:
        samples_for_report = utils.split_str_list(samples_for_report)

    if type(samples_for_report) == list:
        samples_for_report = sample_annotation_df.loc[
            sample_annotation_df["Batch Name"].isin(samples_for_report), "Sample name"
        ].values.tolist()
    else:
        if not pd.Series(
            sample_annotation_df["Batch Name"] == int(samples_for_report)
        ).any():
            logger.warning(
                "Samples_for_report parameter was not found as batch in cohort. All samples reports will be printed."
            )
            return sample_annotation_df.loc[:, "Sample name"].values.tolist()
        samples_for_report = sample_annotation_df.loc[
            sample_annotation_df["Batch Name"] == int(samples_for_report), "Sample name"
        ].values.tolist()
    return samples_for_report


def write_patient_reports(
    results_folder: Union[str, Path],
    measure_dfs,
    topas_scores,
    topas_subscores,
    kinase_scores,
    protein_scores,
    samples_for_report,
    topas_annotation_df: pd.DataFrame,
):
    report_folder = os.path.join(results_folder, "Reports")
    os.makedirs(report_folder, mode=0o700, exist_ok=True)

    # Create reports (~13 seconds per patient report, or ~11 minutes in total on 4 cores for 192 patients)
    logger.info("Queueing reports for multiprocessing")

    # TODO: make the number of cores configurable in the config.json
    # each extra core adds ~300MB extra memory
    processingPool = JobPool(
        processes=6,
        total_jobs=len(samples_for_report),
        max_jobs_queued=10,
        print_progress_every=1,
    )
    # annotation_dfs is ~135MB
    annotation_dfs = get_annotation_dfs(measure_dfs)

    for patient in samples_for_report:
        report_file = os.path.join(report_folder, f"{patient}_proteomics_results.xlsx")
        if os.path.exists(report_file):
            processingPool.applyAsync(create_patient_report_dummy, ())
            continue

        # patient data is ~70MB per patient
        patient_data = create_patient_data(measure_dfs, patient)
        patient_data |= create_patient_topas_score_data(
            patient,
            topas_scores,
            topas_subscores,
            kinase_scores,
            protein_scores,
        )

        processingPool.applyAsync(
            create_patient_report,
            [
                report_file,
                patient,
                patient_data,
                annotation_dfs,
                topas_annotation_df,
            ],
        )

    processingPool.checkPool(printProgressEvery=1)


def create_patient_report_dummy():
    return


def create_patient_data(measure_dfs, patient: str):
    # save patient column from each metric measure dataframe to patient dict for both data types
    patient_data = {}
    for data_type, dfs in measure_dfs.items():
        patient_columns = {
            "Rank": dfs["measures"]["rank"].loc[:, "rank_" + patient],
            "Occurrence": dfs["measures"]["rank"].loc[:, "rank_max"],
            "FC": dfs["measures"]["fold_change"].loc[:, "fc_" + patient],
            "Z-score": dfs["measures"]["z-score"].loc[:, "zscore_" + patient],
            "P-value": dfs["measures"]["p-value"].loc[:, "pvalue_zscore_" + patient],
        }
        if "batch_rank" in dfs["measures"]:
            patient_columns |= {
                "Batch Rank": dfs["measures"]["batch_rank"].loc[
                    :, "batch_rank_" + patient
                ]
            }
        patient_columns |= {
            "Intensity": dfs["scores"].loc[:, patient],
            "Identification metadata": dfs["scores"].loc[
                :, f"Identification metadata {patient.split('pat_')[1]}"
            ],
        }
        patient_data[data_type] = pd.DataFrame.from_dict(patient_columns)
    return patient_data


def get_annotation_dfs(measure_dfs) -> Dict[str, pd.DataFrame]:
    annotation_columns_patient = {}
    for data_type, dfs in measure_dfs.items():
        annotation_columns_patient[data_type] = dfs["scores"][
            ANNOTATION_COLUMNS[data_type].keys()
        ].copy()
    return annotation_columns_patient


def create_patient_report(
    report_file: Union[str, Path],
    patient: str,
    patient_data: Dict,
    annotation_dfs: Dict[str, pd.DataFrame],
    topas_annotation_df: pd.DataFrame,
) -> None:
    annotation_columns_topas = {
        "rank_" + patient: "Rank",
        "occurrence": "Occurrence",
        "zscore_" + patient: "Z-score",
        **TOPAS_SCORE_COLUMNS,
        **TOPAS_SUBSCORE_COLUMNS,
        "batch_rank_" + patient: "Batch Rank",
        "batch_occurrence_" + patient: "Batch Occurrence",
    }

    # # Create a Pandas Excel writer using XlsxWriter as the engine
    with pd.ExcelWriter(report_file, engine="xlsxwriter") as writer:
        # Create TOPAS score worksheets
        for score_type in ["TOPAS scores", "TOPAS subscores"]:
            create_topas_worksheet(
                score_type, patient_data, writer, annotation_columns_topas
            )

        # Create proteome worksheets
        for data_type in ["fp", "pp"]:
            data_type_long = "Proteome"
            create_worksheet = create_fp_worksheet
            if data_type == "pp":
                data_type_long = "Phosphoproteome"
                create_worksheet = create_pp_worksheet
            # else:
            # create_biomarker_worksheet(biomarkers, patient, dfs['metadata'], writer)
            create_worksheet(
                data_type_long,
                annotation_dfs[data_type],
                patient_data[data_type],
                writer,
                ANNOTATION_COLUMNS[data_type],
            )

        # Create Kinase and Protein phosphorylation scoring worksheets
        for sheet_name in [
            "Substrate phosphorylation score",
            "Protein phosphorylation score",
        ]:
            create_wp2_worksheet(
                sheet_name,
                patient_data,
                writer,
                annotation_columns_topas,
                topas_annotation_df,
            )


# move further up in flow here
def create_patient_topas_score_data(
    patient: str,
    topas_scores: Dict[str, Dict[str, pd.DataFrame]],
    topas_subscores: Dict[str, Dict[str, pd.DataFrame]],
    kinase_scores: Dict[str, Dict[str, pd.DataFrame]],
    protein_scores: Dict[str, Dict[str, pd.DataFrame]],
) -> Dict[str, pd.DataFrame]:
    scoring_types = {
        "TOPAS scores": topas_scores,
        "TOPAS subscores": topas_subscores,
        "Substrate phosphorylation score": kinase_scores,
        "Protein phosphorylation score": protein_scores,
    }

    patient_data = {}
    for scoring, scoring_dfs in scoring_types.items():
        patient_data[scoring] = scoring_dfs["scores"].loc[:, patient]
        patient_data[scoring + "_significance"] = (
            scoring_dfs["significance"].loc[:, patient].rename("Significance")
        )

        if scoring == "Substrate phosphorylation score":
            patient_data[scoring] = pd.concat(
                [
                    patient_data[scoring],
                    kinase_scores["targets"]
                    .loc[:, "targets_" + patient.split("pat_")[1]]
                    .rename("Targets"),
                ],
                axis=1,
            )

        patient_data[scoring + "_measures"] = pd.concat(
            [
                scoring_dfs["measures"]["rank"].loc[:, "rank_" + patient],
                scoring_dfs["measures"]["z-score"].loc[:, "zscore_" + patient],
                scoring_dfs["measures"]["occurrence"],
                scoring_dfs["measures"]["batch_rank"].loc[:, "batch_rank_" + patient],
                scoring_dfs["measures"]["batch_occurrence"].loc[
                    :, "batch_occurrence_" + patient
                ],
            ],
            axis=1,
        )

    return patient_data


def create_fp_worksheet(
    sheet_name: str,
    fp: pd.DataFrame,
    df: pd.DataFrame,
    writer: pd.ExcelWriter,
    fp_annotation_columns: Dict[str, str],
) -> None:
    """
    Describe
    :param sheet_name:
    :param fp: patients intensities plus metadata and TOPAS annotations
    :param df: measures fc, rank, z-score etc
    :param writer:
    :param fp_annotation_columns:

    """
    annotations = fp[fp_annotation_columns.keys()]
    annotations = annotations.reindex(fp_annotation_columns.keys(), axis=1)
    annotations = annotations.rename(fp_annotation_columns, axis="columns")

    df = pd.concat([df, annotations], axis=1)

    # Get the xlsxwriter workbook and worksheet objects
    worksheet, workbook = create_workbook(df, writer, sheet_name)

    # Add cell formats
    format_no_dec = workbook.add_format({"num_format": "#,##0"})
    format_two_dec = workbook.add_format({"num_format": "#,##0.00"})
    format_p_value = workbook.add_format({"num_format": "0.00E+00"})
    worksheet.set_column("A:A", 15)  # gene name
    worksheet.set_column("B:C", 12, format_no_dec)  # rank and occurrence
    worksheet.set_column("D:E", 12, format_two_dec)  # fold change and z-score
    worksheet.set_column("F:F", 12, format_p_value)  # p-value
    worksheet.set_column("G:G", 12, format_two_dec)  # intensity
    worksheet.set_column("H:H", 25)  # ident metadata num of peptides
    worksheet.set_column("I:J", 15)  # topas annot and poi annot


def create_pp_worksheet(
    sheet_name: str,
    pp: pd.DataFrame,
    df: pd.DataFrame,
    writer: pd.ExcelWriter,
    pp_annotation_columns: Dict[str, str],
) -> None:
    annotations = pp[pp_annotation_columns.keys()]
    annotations = annotations.reindex(
        pp_annotation_columns.keys(), axis=1
    )  # force correct column order
    annotations = annotations.rename(pp_annotation_columns, axis="columns")

    df = pd.concat([df, annotations], axis=1)
    df = df.reset_index().set_index("Modified sequence")

    # move Gene names and Proteins annot to start of df
    locations, col_names = [0, 10], ["Gene names", "Proteins"]
    df = move_columns_to_start(df, locations, col_names)

    # Get the xlsxwriter workbook and worksheet objects
    worksheet, workbook = create_workbook(df, writer, sheet_name)

    # Add cell formats
    format_no_dec = workbook.add_format({"num_format": "#,##0"})
    format_two_dec = workbook.add_format({"num_format": "#,##0.00"})
    format_p_value = workbook.add_format({"num_format": "0.00E+00"})
    worksheet.set_column("A:A", 22)  # modified sequence
    worksheet.set_column("B:B", 15)  # gene names
    worksheet.set_column("C:D", 15, format_no_dec)  # Rank and occurrence
    worksheet.set_column("E:F", 12, format_two_dec)  # Fold change and z-score
    worksheet.set_column("G:G", 12, format_p_value)  # p-value
    worksheet.set_column("H:H", 12, format_no_dec)  # Z-score rank inside batch
    worksheet.set_column("I:I", 12, format_two_dec)  # intensity
    worksheet.set_column("J:J", 25)  # ident metadata imputed
    worksheet.set_column(
        "K:M", 13
    )  # topas annot, protein names, topas sub annot, poi annot # TODO: reorder
    worksheet.set_column("N:X", 13)  # PSP annotations
    # worksheet.set_column('Y:Y', 20)               # PSP URL


def create_wp2_worksheet(
    sheet_name: str,
    dfs: Dict[str, pd.DataFrame],
    writer: pd.ExcelWriter,
    extra_annotation_columns: Dict[str, str],
    topas_annotation_df: pd.DataFrame,
) -> None:
    valid_columns = list(
        set(extra_annotation_columns.keys()).intersection(
            dfs[f"{sheet_name}_measures"].columns
        )
    )
    measures = dfs[sheet_name + "_measures"][valid_columns]
    significance_score = dfs[sheet_name + "_significance"]
    if sheet_name == "Substrate phosphorylation score":
        significance_score = significance_score.reset_index(
            level="No. of total targets", drop=True
        )

    index_values = "Gene names"
    for score_type in TOPAS_SCORE_COLUMNS.keys():
        # for i, score_type in enumerate(['POI']):
        # use dictionary to assign TOPAS annotation - NB! has to be dataframe
        if sheet_name == "Substrate phosphorylation score":
            index_values = "PSP Kinases"

        topas_df = measures.index.get_level_values(index_values).to_frame()

        data_type = "fp"
        if score_type == "POI_category":
            data_type = "POI"
        annot_dict = clinical_tools.create_identifier_to_topas_dict(
            topas_annotation_df, data_type
        )

        topas_df[score_type] = topas_df.apply(
            clinical_tools.map_identifier_list_to_annot_types,
            annot_dict=annot_dict,
            annot_type=score_type,
            with_weights=False,
            axis=1,
        )

        topas_df.index = measures.index
        if sheet_name == "Substrate phosphorylation score":
            topas_df = topas_df.drop(["PSP Kinases"], axis=1)
        else:
            topas_df = topas_df.drop("Gene names", axis=1)
        measures = pd.merge(left=measures, right=topas_df, on=index_values)
    for topas_score in TOPAS_SCORE_COLUMNS.keys():
        # remove duplicated TOPAS annotations
        measures[topas_score] = measures[topas_score].apply(get_unique_topas_names)

    # rename the metric columns and TOPAS score
    measures = measures.rename(extra_annotation_columns, axis="columns")

    if sheet_name == "Protein phosphorylation score":
        wp2_score = dfs[sheet_name]
        df_subset = [
            "Score",
            "Rank",
            "Occurrence",
            "Z-score",
            "Significance",
            *TOPAS_SCORE_COLUMNS.values(),
            "Batch Rank",
            "Batch Occurrence",
        ]
    else:
        wp2_score = dfs[sheet_name].reset_index(level="No. of total targets")
        df_subset = [
            "No. of total targets",
            "Score",
            "Targets",
            "Rank",
            "Occurrence",
            "Z-score",
            "Significance",
            *TOPAS_SCORE_COLUMNS.values(),
            "Batch Rank",
            "Batch Occurrence",
        ]
        wp2_score.columns = [
            "No. of total targets",
            "Score",
            "Targets",
        ]  # is this needed?
    if isinstance(wp2_score, pd.Series):
        wp2_score = wp2_score.to_frame(
            name="Score"
        )  # Convert Series to DataFrame with column name

    df = pd.concat([wp2_score, measures, significance_score], axis=1)
    df.index.name = (
        "Kinase" if sheet_name == "Substrate phosphorylation score" else "Protein"
    )
    if topas_annotation_df is not None:
        df = df[df_subset]

    # Get the xlsxwriter workbook and worksheet objects
    worksheet, workbook = create_workbook(df, writer, sheet_name)

    # Add cell formats
    format_no_dec = workbook.add_format({"num_format": "#,##0"})
    format_two_dec = workbook.add_format({"num_format": "#,##0.00"})

    if sheet_name == "Substrate phosphorylation score":
        worksheet.set_column("A:A", 20)  # Kinase
        worksheet.set_column("B:B", 20, format_no_dec)  # targets of cohort
        worksheet.set_column("C:C", 14, format_two_dec)  # score
        worksheet.set_column(
            "D:F", 12, format_no_dec
        )  # targets in sample + rank + occurrence
        worksheet.set_column("G:G", 14, format_two_dec)  # z-score
        worksheet.set_column("H:H", 15, format_no_dec)  # significance
        worksheet.set_column("I:J", 15, format_no_dec)  # topas annot+poi annot
        worksheet.set_column("K:L", 17, format_no_dec)  # rank+occurrence in batch

    if sheet_name == "Protein phosphorylation score":
        worksheet.set_column("A:A", 20)  # Protein
        worksheet.set_column("B:B", 16, format_two_dec)  # score
        worksheet.set_column("C:D", 12, format_no_dec)  # rank + occurrence
        worksheet.set_column("E:E", 14, format_two_dec)  # z-score
        worksheet.set_column("F:F", 15, format_no_dec)  # significance
        worksheet.set_column("G:H", 15, format_no_dec)  # topas annot+poi annot
        worksheet.set_column("I:J", 17, format_no_dec)  # rank+occurrence in batch


def create_topas_worksheet(
    sheet_name: str,
    dfs: Dict[str, pd.DataFrame],
    writer: pd.ExcelWriter,
    extra_annotation_columns: Dict[str, str],
) -> None:
    dfs[sheet_name] = dfs[sheet_name].to_frame(name="Score")

    valid_columns = [
        col
        for col in extra_annotation_columns.keys()
        if col in dfs[f"{sheet_name}_measures"].columns
    ]
    measures = dfs[sheet_name + "_measures"][valid_columns]
    measures = measures.rename(extra_annotation_columns, axis="columns")
    significance_score = dfs[sheet_name + "_significance"]

    # combine with patient data
    df = pd.concat([dfs[sheet_name], measures, significance_score], axis=1)

    if sheet_name == "TOPAS subscores":
        # split TOPAS_subscore_level into TOPAS score, TOPAS subscore and level of score
        df.index = df.index.str.split(" - ", expand=True)
        df.index.names = ["Kinase", "TOPAS score level", "Data level"]
    else:
        df.index.name = "Kinase"

    # Get the xlsxwriter workbook and worksheet objects
    worksheet, workbook = create_workbook(df, writer, sheet_name)

    # Add cell formats
    format_no_dec = workbook.add_format({"num_format": "#,##0"})
    format_two_dec = workbook.add_format({"num_format": "#,##0.00"})
    if sheet_name == "TOPAS scores":
        worksheet.set_column("A:A", 20)  # topas kinase
        worksheet.set_column("B:B", 15, format_two_dec)  # topas score
        worksheet.set_column("C:C", 12, format_no_dec)  # rank
        worksheet.set_column("D:D", 15, format_no_dec)  # occurrence
        worksheet.set_column("E:E", 12, format_two_dec)  # z-score
        worksheet.set_column(
            "F:H", 15, format_no_dec
        )  # significance+zscore rank in batch+occurrence in batch
        worksheet.set_column(
            "I:M", 22, format_no_dec
        )  # no. sign scores in topas subscores
    else:
        worksheet.set_column("A:B", 20)  # TOPAS score + subscore
        worksheet.set_column("C:C", 25)  # level
        worksheet.set_column("D:D", 15, format_two_dec)  # topas subscore
        worksheet.set_column("E:E", 12, format_no_dec)  # rank
        worksheet.set_column("F:F", 15, format_no_dec)  # occurrence
        worksheet.set_column("G:G", 12, format_two_dec)  # z-score
        worksheet.set_column("H:H", 15, format_no_dec)  # significance
        worksheet.set_column(
            "I:J", 15, format_no_dec
        )  # rank in batch+occurrence in batch


def create_workbook(
    patient_data: pd.DataFrame, writer, sheet_name: str, use_index: bool = True
):
    patient_data.to_excel(
        writer, sheet_name=sheet_name, index=use_index, merge_cells=False
    )  # this is the slow part...
    workbook, worksheet = writer.book, writer.sheets[sheet_name]
    return worksheet, workbook


def move_columns_to_start(df, locations, col_names):
    df_new = df.drop(labels=col_names, axis=1)
    for location, col_name in zip(locations, col_names):
        df_new.insert(location, col_name, df[col_name])
    df = df_new
    return df


def assign_significance_score(col: pd.Series):
    score_percentage_thresholds = [0.05, 0.10, 0.20, 0.90]
    sorted_col = col.sort_values(ascending=False)
    for i, threshold in enumerate(score_percentage_thresholds):
        previous_threshold_percentage = math.ceil(
            col.size * score_percentage_thresholds[i - 1]
        )
        top_threshold_percentage = math.ceil(col.size * threshold)
        if i == 0:
            col.loc[sorted_col.iloc[:top_threshold_percentage].index] = i + 1
        if i == 3:
            col.loc[sorted_col.iloc[top_threshold_percentage:].index] = i + 1
            col.loc[
                sorted_col.iloc[
                    previous_threshold_percentage:top_threshold_percentage
                ].index
            ] = np.nan
        else:
            col.loc[
                sorted_col.iloc[
                    previous_threshold_percentage:top_threshold_percentage
                ].index
            ] = (i + 1)
    return col


if __name__ == "__main__":
    import argparse

    from . import config

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-c", "--config", required=True, help="Absolute path to configuration file."
    )
    args = parser.parse_args(sys.argv[1:])

    configs = config.load(args.config)

    create_report(
        results_folder=configs.results_folder,
        debug=configs.preprocessing.debug,
        report_config=configs.report,
        annot_file=configs.clinic_proc.prot_baskets,
        data_types=configs.data_types,
    )
