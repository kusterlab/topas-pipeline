"""
Collects quality control (QC) statistics from all MaxQuant searches for the MTB portal.
"""
import os
import sys
import argparse
import warnings
import logging
from pathlib import Path

import pandas as pd

from . import config as config
from . import sample_annotation as sa
from . import meta_input_file as mi

sys.path.append('../')
from .qc import maxquant_search_qc_plots

# hacky way to get the package logger instead of just __main__ when running as module
logger = logging.getLogger(__package__ + "." + __file__)


def maxquant_qc(*args, **kwargs) -> None:
    data_types = kwargs.pop("data_types")
    sample_annotation = kwargs.pop("sample_annot")
    for data_type in data_types:
        maxquant_qc_data_type(*args, **kwargs, data_type=data_type, sample_annot=sample_annotation)


def maxquant_qc_data_type(results_folder: str, data_type: str, sample_annot: str) -> None:
    maxquant_qc_table_file = Path(results_folder) / f"maxquant_qc_table_{data_type}.tsv"
    if maxquant_qc_table_file.exists():
        logger.info(f'MaxQuant QC for {data_type} skipped - found previously generated "maxquant_qc_table_{data_type}.tsv".')
        return

    meta_input_file = mi.get_meta_input_file_path(results_folder, data_type)
    if not meta_input_file.exists():
        # TODO: generate meta input file regardless of SIMSI
        logger.error("Could not find meta input file {meta_input_file.name} generated by SIMSI, skipping MaxQuant QC...")
        return
    
    meta_input_df = mi.read_meta_input_file(meta_input_file)

    qc_stats_dfs = []
    for mq_txt_folder in map(Path, meta_input_df["mq_txt_folder"]):
        qc_stats_file = mq_txt_folder / "QC_plots" / f"ID_table_{data_type.upper()}.csv"

        # Here only looping through batches in this cohort
        # if not qc_stats_file.exists():
        generate_qc_plots(mq_txt_folder.parent.parent, data_type)

        qc_stats_dfs.append(read_qc_stats_file(qc_stats_file))

    qc_stats_df = pd.concat(qc_stats_dfs, ignore_index=True)
    qc_stats_df = qc_stats_df.reset_index(drop=True)

    # TODO: move this to a separate function/reuse functionality from sample_annotation.py
    # map sample names
    sample_annotation_df = sa.load_sample_annotation(sample_annot)
    sample_annotation_df = sa.filter_sample_annotation(sample_annotation_df, remove_qc_failed=True, remove_replicates=True)

    def generate_channel_name(x):
        # return f"Reporter intensity corrected {x['TMT Channel']} {x['Cohort']}_Batch{add_leading_zero(x['Batch Name'])}"
        return f"Reporter intensity corrected {x['TMT Channel']} Batch{x['Batch Name']}"

    sample_annotation_df["channel"] = sample_annotation_df[
        ["TMT Channel", "Cohort", "Batch Name"]
    ].apply(generate_channel_name, axis=1)

    channel_to_sample_id_dict = dict(
        zip(
            sample_annotation_df["channel"].tolist(),
            sample_annotation_df["Sample name"].tolist(),
        ))

    # add prefic Reporter intensity corrected to the channel names
    qc_stats_df["Channel"] = qc_stats_df["Channel"].apply(lambda x: f"Reporter intensity corrected {x}")

    # remove anything that comes after first _ in Experiment column
    qc_stats_df["Experiment"] = qc_stats_df["Experiment"].str.split("_").str[0]

    # combine Channel with Experiment
    qc_stats_df["Channel"] = qc_stats_df["Channel"] + " " + qc_stats_df["Experiment"]
    # Map Channel to sample names using dictionary channel_to_sample_id_dict
    qc_stats_df["Sample"] = qc_stats_df["Channel"].map(channel_to_sample_id_dict)

    qc_stats_df.to_csv(
        maxquant_qc_table_file, sep="\t", index=False
    )

    logger.info(f"Results have been written to {maxquant_qc_table_file}")


def generate_qc_plots(mq_folder_base_path: Path, data_type: str):
    logger.info(f"Generating QC plots for {mq_folder_base_path.name}")
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=pd.errors.DtypeWarning)
        maxquant_search_qc_plots.main([str(mq_folder_base_path), data_type.upper()])


def read_qc_stats_file(qc_stats_file: Path):
    qc_stats_df = pd.read_csv(qc_stats_file)
    qc_stats_df = qc_stats_df[
        qc_stats_df["Channel"].notna() & (qc_stats_df["Channel"] != "total")
    ]
    qc_stats_df = qc_stats_df.dropna(axis=1, how="all")
    return qc_stats_df


def find_files_with_name(root_folder, target_file_name):
    file_paths = []
    
    # Walk through all the directories and subdirectories
    for foldername, subfolders, filenames in os.walk(root_folder):
        for filename in filenames:
            # Check if the current file has the desired name
            if filename == target_file_name:
                # If yes, append the full path to the list
                file_paths.append(os.path.join(foldername, filename))
    
    return file_paths


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-c",
        "--config",
        dest="config",
        required=False,
        help="Absolute path to configuration file.",
    )

    args = parser.parse_args(sys.argv[1:])

    configs = config.load(args.config)

    # only when results folder given the stats files will be saved in the results folder for batches in the cohort
    maxquant_qc(configs["results_folder"], data_types=configs["data_types"], sample_annot=configs["sample_annotation"])

