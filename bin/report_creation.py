import os.path
import sys
import json
import math
import logging
import time

import numpy as np
import pandas as pd
from pathlib import Path
from typing import Tuple, List, Dict, Union
from job_pool import JobPool

import bin.sample_annotation as sa
import bin.utils as utils
import bin.metrics as metrics
import bin.clinical_process as clinical_process
import bin.clinical_tools as clinical_tools
import bin.basket_scoring as basket_scoring
import bin.TOPAS_kinase_scoring as kinase_scoring
import bin.TOPAS_protein_phosphorylation_scoring as protein_phoshorylation_scoring

logger = logging.getLogger(__name__)


def create_report(results_folder: Union[str, Path],
                  debug: bool,
                  samples_for_report: str,
                  drug_list_file: Union[str, Path],
                  data_types: List[str]) -> None:
    """Creates an Excel report for each sample
    Requires that annot_{data_type}.csv is generated by clinical_process.py
    Requires that [phospho|full_proteome]_[z|rank|p|fc].csv files are generated by metrics.py
    # TODO: should require that kinase and phospho scoring files are generated (by proper exception handling if not)
    kinase_scores.tsv
    protein_scores.tsv
    """
    logger.info('Running report creation module')

    # TODO: add a check that batch selected exists in data and optimize this whole functionality.. rarely ever use it because it's too complicated
    if samples_for_report == "none":
        return
    if samples_for_report in ['all', 'ALL', '']:
        samples_list = []
    else:
        try:
            samples_for_report = str(samples_for_report)
        except ValueError:
            print('Input not of type int or string')
        samples_list = samples_for_report

    # Read basket scoring dictionary from json
    basket_annot_dicts = get_basket_annot_dicts(results_folder, data_types)

    # Load sample annotation file
    sample_annotation_df = sa.load_sample_annotation(os.path.join(results_folder, 'sample_annot_filtered.csv'))
    sample_annotation_df = sa.filter_sample_annotation(sample_annotation_df, remove_qc_failed=False, remove_replicates=False, remove_reference=True)
    sample_annotation_df = sample_annotation_df.sort_values(by='Batch Name')

    # Read scoring files and calculate extra annotation metrics
    basket_scores, subbasket_scores, kinase_scores, protein_scores = read_and_compute_scores(results_folder)

    #TODO: it would make a lot of sense to move these calculations to it's own module and have a report writing only module which can be reused on portal
    # Questio is HOW to make it fast and efficient (takes a lot of memory to read all the data now. Do we need to read and close one file at a time?) 

    # Calculate in batch basket scores
    batch_basket_scores, batch_subbasket_scores, batch_kinase_scores, batch_protein_scores, batch_phospho_scores = dict(), dict(), dict(), dict(), dict()
    batch_basket_scores['measures'] = compute_in_batch_rank(basket_scores['scores'], sample_annotation_df)
    batch_subbasket_scores['measures'] = compute_in_batch_rank(subbasket_scores['scores'], sample_annotation_df)
    batch_kinase_scores['measures'] = compute_in_batch_rank(kinase_scores['scores'], sample_annotation_df)
    batch_protein_scores['measures'] = compute_in_batch_rank(protein_scores['scores'], sample_annotation_df)

    # Read and prepare patient intensity data + quant measures (fc, z-score)
    measure_dfs = dict()
    for data_type in data_types:
        measures = metrics.read_measures(results_folder, data_type)
        annot, _ = clinical_process.read_annotation_files(results_folder, debug, data_type)
        measure_dfs[data_type] = {'metrics': measures, 'metadata': annot}
        if len(samples_list) == 0:
            samples_for_report = measures['z-score'].filter(regex=r'zscore').columns.tolist()
        else:
            samples_for_report = get_samples_for_report(sample_annotation_df, samples_list)
    batch_phospho_scores['measures'] = compute_in_batch_rank(measure_dfs['pp']['metrics']['z-score'], sample_annotation_df)

    samples_for_report.reverse() # print reports for newest batch first
    write_patient_reports(results_folder, measure_dfs, basket_scores, batch_basket_scores, subbasket_scores,
                          batch_subbasket_scores, kinase_scores, batch_kinase_scores, protein_scores, batch_protein_scores,
                          batch_phospho_scores, samples_for_report, basket_annot_dicts, sample_annotation_df)


def get_basket_annot_dicts(results_folder, data_types):
    basket_annot_dicts = {}
    for data_type in data_types + ['fp_with_ref', 'pp_with_ref']:
        # try to loop through data types and when a fitting dict is found load it
        if os.path.exists(os.path.join(results_folder, f'topas_annot_dict_{data_type}.json')):
            f = open(os.path.join(results_folder, f'topas_annot_dict_{data_type}.json'))
            f_poi = open(os.path.join(results_folder, f'poi_annot_dict_{data_type}.json'))
            if 'fp' in data_type:
                data_type = 'fp'
            else:
                data_type = 'pp'
            basket_annot_dicts[data_type] = json.load(f)
            basket_annot_dicts['poi'] = json.load(f_poi)
    return basket_annot_dicts


def read_and_compute_scores(results_folder: Union[str, Path]) -> Tuple:
    # TODO: optimize reading and filtering of score files
    basket_scores, subbasket_scores, kinase_scores, protein_scores = dict(), dict(), dict(), dict()
    basket_scores['scores'] = basket_scoring.read_basket_scores(results_folder).transpose()
    basket_scores['scores'] = basket_scores['scores'].loc[:, ~basket_scores['scores'].columns.str.startswith('target')]

    subbasket_scores['scores'] = basket_scoring.read_sub_basket_scores(results_folder)
    subbasket_scores['scores'] = subbasket_scores['scores'].loc[:, ~subbasket_scores['scores'].columns.str.startswith('target')]

    kinase_scores['scores'] = kinase_scoring.read_kinase_scoring(results_folder)
    kinase_scores['targets'] = kinase_scores['scores'].filter(regex=r'target')
    kinase_scores['scores'] = kinase_scores['scores'].loc[:, ~kinase_scores['scores'].columns.str.startswith('target')]
    kinase_scores['scores'] = kinase_scores['scores'].filter(regex='pat_')

    protein_scores['scores'] = protein_phoshorylation_scoring.read_protein_scoring(results_folder)
    protein_scores['scores'] = protein_scores['scores'].loc[:, ~protein_scores['scores'].columns.str.startswith('target')]

    all_scores = [basket_scores, subbasket_scores, kinase_scores, protein_scores]
    for score_dict in all_scores:
        if 'No. of total targets' in score_dict['scores'].columns:
            score_dict['scores'] = score_dict['scores'].drop(columns='No. of total targets')
    all_scores_copy = [basket_scores['scores'].copy(), subbasket_scores['scores'].copy(), kinase_scores['scores'].copy(),
                       protein_scores['scores'].copy()]

    for i, score_dict in enumerate(all_scores):
        score_dict['measures'] = metrics.compute_measures(score_dict['scores'])
        score_dict['significance'] = all_scores_copy[i].apply(assign_significance_score, axis=1)
    return basket_scores, subbasket_scores, kinase_scores, protein_scores


def compute_in_batch_rank(basket_scores: pd.DataFrame, sample_annotation_df: pd.DataFrame) -> Dict:
    basket_scores_copy = basket_scores.copy()  # copy necessary to not alter original df
    if 'zscore' in basket_scores_copy.columns[1]:
        basket_scores_copy.columns = basket_scores_copy.columns.str.replace('zscore_', '') 
    # Create a mapping of patient columns to batch names directly
    sample_batch_dict = dict(zip(
        sample_annotation_df.transpose().add_prefix('pat_').columns.tolist(),
        sample_annotation_df['Batch Name'].values.tolist()
    ))

    # Map each sample to its respective batch
    samples_as_baskets = [sample_batch_dict[sample] for sample in basket_scores_copy.columns]

    rank_values = {}
    for batch in set(samples_as_baskets):
        batch_mask = np.array(samples_as_baskets) == batch
        batch_scores = basket_scores_copy.loc[:, batch_mask]
        ranks = metrics.Metrics.get_rank(batch_scores)

        # Get occurrences and store results for current batch in dict
        occurrences = ranks['rank_max']
        occurrences.name = 'occurrence'
        ranks = ranks.drop(columns='rank_max')
        occurrences.to_frame()
        rank_values[batch] = {'ranks': ranks, 'occurrence': occurrences}
    return rank_values


# TODO: find out what this was about. An attempt at optimizing?
def new_compute_in_batch_scores(basket_scores: pd.DataFrame, sample_annotation_df: pd.DataFrame) -> Dict:
    common_samples = [x for x in sample_annotation_df['Sample name'].tolist() if x in basket_scores.columns.tolist() ]
    common_sample_annotation_df = sample_annotation_df[sample_annotation_df['Sample name'].isin(common_samples)]
    common_sample_annotation_df = common_sample_annotation_df[['Sample name','Batch Name']]

    all_batches = common_sample_annotation_df['Batch Name'].unique().tolist()
    all_measures = dict()
    for batch in all_batches:
        batch_mask = common_sample_annotation_df['Sample name'][common_sample_annotation_df['Batch Name'] == batch].tolist()
        all_measures[batch] = metrics.compute_measures(basket_scores.loc[:, batch_mask])
    return all_measures


def get_samples_for_report(sample_annotation_df: pd.DataFrame, samples_for_report):
    #samples_for_report = []
    # TODO: add test for this ? to crash with a message at least
    if ',' in samples_for_report or ';' in samples_for_report:
        samples_for_report = utils.split_str_list(samples_for_report)
    if type(samples_for_report) == list:
        samples_for_report = sample_annotation_df.loc[
            sample_annotation_df['Batch Name'].isin(samples_for_report), 'Sample name'].values.tolist()
    else:
        if not pd.Series(sample_annotation_df['Batch Name'] == int(samples_for_report)).any():
            logger.warning('Samples_for_report parameter was not found as batch in cohort. All samples reports will be printed.')
            return sample_annotation_df.loc[:, 'Sample name'].values.tolist()
        samples_for_report = sample_annotation_df.loc[
            sample_annotation_df['Batch Name'] == int(samples_for_report), 'Sample name'].values.tolist()
    return samples_for_report


def write_patient_reports(results_folder: Union[str, Path],
                          measure_dfs,
                          basket_scores,
                          batch_basket_scores,
                          subbasket_scores,
                          batch_subbasket_scores,
                          kinase_scores,
                          batch_kinase_scores,
                          protein_scores,
                          batch_protein_scores,
                          batch_phospho_scores,
                          samples_for_report,
                          basket_annot_dicts: List[Union[Dict, None]],
                          sample_annotation_df,
                        #   biomarkers: pd.DataFrame
                          ):
    report_folder = os.path.join(results_folder, 'Reports')
    os.makedirs(report_folder, mode=0o700, exist_ok=True)

    # Create reports (~13 seconds per patient report, or ~11 minutes in total on 4 cores for 192 patients)
    logger.info('Queueing reports for multiprocessing')

    # TODO: make the number of cores configurable in the config.json
    processingPool = JobPool(processes=6)
    for i, patient in enumerate(samples_for_report):
        if 'zscore' in patient:
            patient = patient.split('zscore_')[1]
        batch = sample_annotation_df.loc[patient.split('pat_')[1], 'Batch Name']
        report_file = os.path.join(report_folder, f'{patient}_proteomics_results.xlsx')
        if os.path.exists(report_file):
            continue
        processingPool.applyAsync(create_patient_report, [report_file, patient, measure_dfs, basket_scores, batch_basket_scores,
                                                          subbasket_scores, batch_subbasket_scores, kinase_scores, batch_kinase_scores,
                                                          protein_scores, batch_protein_scores, batch_phospho_scores, basket_annot_dicts, batch])
        # for debugging purpose :)
        # create_patient_report(report_file, patient, measure_dfs, basket_scores, batch_basket_scores, subbasket_scores,
        #                      batch_subbasket_scores, kinase_scores, batch_kinase_scores, protein_scores, batch_protein_scores,
        #                      batch_phospho_scores, basket_annot_dicts, batch)  # useful for debugging

    processingPool.checkPool(printProgressEvery=1)


def create_patient_report(report_file: Union[str, Path],
                          patient: str,
                          metrics_dfs: Dict[str, Dict[str, pd.DataFrame]],
                          basket_scores: Dict[str, Dict[str, pd.DataFrame]],
                          batch_basket_score: Dict[str, Dict[str, pd.DataFrame]],
                          subbasket_scores: Dict[str, Dict[str, pd.DataFrame]],
                          batch_subbasket_scores: Dict[str, Dict[str, pd.DataFrame]],
                          kinase_scores: Dict[str, Dict[str, pd.DataFrame]],
                          batch_kinase_scores: Dict[str, Dict[str, pd.DataFrame]],
                          protein_scores: Dict[str, Dict[str, pd.DataFrame]],
                          batch_protein_scores: Dict[str, Dict[str, pd.DataFrame]],
                          batch_phospho_scores: Dict[str, Dict[str, pd.DataFrame]],
                          basket_annot_dicts: List[Union[Dict[str, Dict], None]],
                          batch: int,
                        #   biomarkers: pd.DataFrame
                          ) -> None:

    # save patient column from each metric measure dataframe to patient dict for both data types
    patient_data = {}
    for data_type, dfs in metrics_dfs.items():
        ranked, fold_change, z_scores, p_values = dfs['metrics'].values()
        patient_data[data_type] = pd.concat([ranked.loc[:, 'rank_' + patient],
                                             ranked.loc[:, 'rank_max'],
                                             fold_change.loc[:, 'fc_' + patient],
                                             z_scores.loc[:, 'zscore_' + patient],
                                             p_values.loc[:, 'pvalue_zscore_' + patient]], axis=1)
        patient_data[data_type].columns = ['Rank', 'Occurrence', 'FC', 'Z-score', 'P-value']
    # sub basket - do we want to keep sarcoma subtype as annotation?
    patient_data = add_scores_to_patient_data(patient_data, patient, basket_scores, batch_basket_score, subbasket_scores,
                                              batch_subbasket_scores, kinase_scores, batch_kinase_scores, protein_scores,
                                              batch_protein_scores, batch_phospho_scores, batch)

    annotation_columns, annotation_columns_baskets = dict(), dict()
    annotation_columns['pp'] = {patient: 'Intensity',
                                f"Identification metadata {patient.split('pat_')[1]}": 'Identification metadata',
                                'TOPAS_score': 'TOPAS annot',
                                'POI': 'POI category',
                                'Site positions identified (MQ)': 'Site positions (MQ identified - PSP)',
                                'Site positions': 'Site positions (PSP)',
                                'PSP Kinases': 'Kinases (PSP)',
                                'PSP_ON_FUNCTION': 'Effects on Modified Protein (PSP)',
                                'PSP_ON_PROCESS': 'Effects on Biological Processes (PSP)',
                                'PSP_ON_PROT_INTERACT': 'Induce Interaction with protein (PSP)',
                                'PSP_ON_OTHER_INTERACT': 'Induce Interaction with other (PSP)',
                                'PSP_NOTES': 'PSP NOTES',
                                'PSP_LT_LIT': 'Low throughput studies (PSP)',
                                'PSP_MS_LIT': 'High throughput studies (PSP)',
                                'PSP_MS_CST': 'CST studies (PSP)',
                                }
    annotation_columns['fp'] = {f"Identification metadata {patient.split('pat_')[1]}": 'Identification metadata',
                                patient: 'Intensity',
                                'TOPAS_score': 'TOPAS annot',
                                'POI': 'POI category',
                                }
    annotation_columns_topas = {'rank_' + patient: 'Rank',
                                  'zscore_' + patient: 'Z-score',
                                  'occurrence': 'Occurrence',
                                  'TOPAS_score': 'TOPAS annot',
                                  'TOPAS_subscore': 'TOPAS sublevel annot',
                                  'POI': 'POI category',}

    # # Create a Pandas Excel writer using XlsxWriter as the engine
    with pd.ExcelWriter(report_file, engine='xlsxwriter') as writer:

        # Create basket worksheets
        score_types = ['TOPAS scores', 'TOPAS subscores']
        for score_type in score_types:
            create_score_worksheet(score_type, patient_data, writer, score_type,
                                    annotation_columns_topas)

        # Create proteome worksheets
        for data_type, dfs in metrics_dfs.items():
            data_type_long = 'Proteome'
            create_worksheet = create_fp_worksheet
            if data_type == 'pp':
                data_type_long = 'Phosphoproteome'
                create_worksheet = create_pp_worksheet
            # else:
                # create_biomarker_worksheet(biomarkers, patient, dfs['metadata'], writer)
            create_worksheet(data_type_long, dfs['metadata'], patient_data, writer, annotation_columns[data_type])

        # Create Kinase and Protein phosphorylation scoring worksheets
        create_wp2_worksheet('Substrate phosphorylation score', patient_data, writer, annotation_columns_topas, basket_annot_dicts)
        create_wp2_worksheet('Protein score', patient_data, writer, annotation_columns_topas, basket_annot_dicts)


# TODO: finish implementation of this function instead
# def new_add_scores_to_patient_data(patient_data: Dict[str, Dict[str, pd.DataFrame]],
#                                 patient: str,
#                                 basket_scores: Dict[str, Dict[str, pd.DataFrame]],
#                                 batch_basket_scores: Dict[str, pd.DataFrame],
#                                 subbasket_scores: Dict[str, Dict[str, pd.DataFrame]],
#                                 batch_subbasket_scores: Dict[str, pd.DataFrame],
#                                 kinase_scores: Dict[str, Dict[str, pd.DataFrame]],
#                                 batch_kinase_scores: Dict[str, pd.DataFrame],
#                                 protein_scores: Dict[str, Dict[str, pd.DataFrame]],
#                                 batch_protein_scores: Dict[str, pd.DataFrame],
#                                 batch_phospho_scores: Dict[str, pd.DataFrame],
#                                 batch: int) -> Dict[str, pd.DataFrame]:
    
#     # Create a dictionary mapping each scoring type to its respective data
#     scoring_data = {
#         'TOPAS scores': (basket_scores, basket_scores['measures'].values(), None),
#         'Batch_TOPAS': (batch_basket_scores, batch_basket_scores['measures'][batch].values(), 'ranks'),
#         'TOPAS subscores': (subbasket_scores, subbasket_scores['measures'].values(), None),
#         'Batch_TOPAS_sub': (batch_subbasket_scores, batch_subbasket_scores['measures'][batch].values(), 'ranks'),
#         'Kinase': (kinase_scores, kinase_scores['measures'].values(), 'targets'),
#         'Batch_Kinase': (batch_kinase_scores, batch_kinase_scores['measures'][batch].values(), 'ranks'),
#         'Protein': (protein_scores, protein_scores['measures'].values(), 'targets'),
#         'Batch_Protein': (batch_protein_scores, batch_protein_scores['measures'][batch].values(), 'ranks'),
#         'Batch_Phospho': (batch_phospho_scores, batch_phospho_scores['measures'][batch].values(), 'ranks')
#     }

#     for scoring, (score_data, measures, target_key) in scoring_data.items():
#         # Check if the scoring type has the "scores" key and process accordingly
#         if 'scores' in score_data:
#             patient_data[scoring] = score_data['scores'].loc[:, patient].rename(f'{scoring} score')
#             patient_data[scoring].index.name = scoring
        
#         # Handle kinase or protein targets if applicable
#         if scoring == 'Kinase' or scoring == 'Protein':
#             patient_data[scoring] = pd.concat([
#                 patient_data[scoring],
#                 score_data['targets'].loc[:, f'targets_{patient.split("pat_")[1]}'].rename('Targets')
#             ], axis=1)

#         # Handle measures (ranks, zscores, occurrences) and concatenate them
#         rank, _, zscore, _, occurrence = measures
#         if zscore is not None:
#             patient_data[f'{scoring}_measures'] = pd.concat([
#                 rank.loc[:, f'rank_{patient}'],
#                 zscore.loc[:, f'zscore_{patient}'],
#                 occurrence
#             ], axis=1)
#         else:
#             patient_data[f'{scoring}_measures'] = pd.concat([
#                 rank.loc[:, f'rank_{patient}'],
#                 occurrence
#             ], axis=1)
#         patient_data[f'{scoring}_measures'].index.name = scoring

#         # Handle significance if available
#         if 'significance' in score_data:
#             patient_data[f'{scoring}_significance'] = score_data['significance'].loc[:, patient].rename('Significance')
#             patient_data[f'{scoring}_significance'].index.name = scoring

#     return patient_data


# move further up in flow here
def add_scores_to_patient_data(patient_data: Dict[str, Dict[str, pd.DataFrame]],
                               patient: str,
                               topas_scores: Dict[str, Dict[str, pd.DataFrame]],
                               batch_topas_scores: Dict[str, pd.DataFrame],
                               topas_subscores: Dict[str, Dict[str, pd.DataFrame]],
                               batch_topas_subscores: Dict[str, pd.DataFrame],
                               kinase_scores: Dict[str, Dict[str, pd.DataFrame]],
                               batch_kinase_scores: Dict[str, pd.DataFrame],
                               protein_scores: Dict[str, Dict[str, pd.DataFrame]],
                               batch_protein_scores: Dict[str, pd.DataFrame],
                               batch_phospho_scores: Dict[str, pd.DataFrame],
                               batch: int) -> Dict[str, pd.DataFrame]:
    topas_rank, _, topas_zscore, _, topas_occurrence = topas_scores['measures'].values()
    batch_topas_rank, _, batch_topas_zscore, _, batch_topas_occurrence = batch_topas_scores['measures'][batch]['ranks'], None, None, None, batch_topas_scores['measures'][batch]['occurrence']
    topas_subscores_rank, _, topas_subscores_zscore, _, topas_subscores_occurrence = topas_subscores['measures'].values()
    batch_topas_subscores_rank, _, batch_topas_subscores_zscore, _, batch_topas_subscores_occurrence = batch_topas_subscores['measures'][batch]['ranks'], None, None, None, batch_topas_subscores['measures'][batch]['occurrence']
    kinase_rank, _, kinase_zscore, _, kinase_occurrence = kinase_scores['measures'].values()
    batch_kinase_rank, _, batch_kinase_zscore, _, batch_kinase_occurrence = batch_kinase_scores['measures'][batch]['ranks'], None, None, None, batch_kinase_scores['measures'][batch]['occurrence']
    protein_rank, _, protein_zscore, _, protein_occurrence = protein_scores['measures'].values()
    batch_protein_rank, _, batch_protein_zscore, _, batch_protein_occurrence = batch_protein_scores['measures'][batch]['ranks'], None, None, None, batch_protein_scores['measures'][batch]['occurrence']
    batch_phospho_rank, _, batch_phospho_zscore, _, batch_phospho_occurrence = batch_phospho_scores['measures'][batch]['ranks'], None, None, None, batch_phospho_scores['measures'][batch]['occurrence']

    scoring_types = ['TOPAS scores', 'Batch TOPAS scores', 'TOPAS subscores', 'Batch TOPAS subscores', 'Substrate phosphorylation score', 'Batch Substrate phosphorylation score', 'Protein score',
                     'Batch Protein score', 'Batch Phospho']
    scoring_ranks = [topas_rank, batch_topas_rank, topas_subscores_rank, batch_topas_subscores_rank, kinase_rank, batch_kinase_rank,
                     protein_rank, batch_protein_rank, batch_phospho_rank]   
    scoring_zscores = [topas_zscore, batch_topas_zscore, topas_subscores_zscore, batch_topas_subscores_zscore, kinase_zscore,
                       batch_kinase_zscore, protein_zscore, batch_protein_zscore, batch_phospho_zscore]
    scoring_occurrences = [topas_occurrence, batch_topas_occurrence, topas_subscores_occurrence, batch_topas_subscores_occurrence,
                           kinase_occurrence, batch_kinase_occurrence, protein_occurrence, batch_protein_occurrence,
                           batch_phospho_occurrence]
    scoring_dfs = [topas_scores, topas_scores, topas_subscores, topas_subscores, kinase_scores, kinase_scores, protein_scores,
                   protein_scores, batch_phospho_scores]

    for i, scoring in enumerate(scoring_types):
        
        if 'scores' in scoring_dfs[i].keys():
            patient_data[scoring] = scoring_dfs[i]['scores'].loc[:, patient]
        else:
            pass

        if scoring == 'Substrate phosphorylation score':
            patient_data[scoring] = pd.concat(
                [patient_data[scoring], kinase_scores['targets'].loc[:, 'targets_' + patient.split('pat_')[1]].rename(
                    'Targets')], axis=1)
        
        if scoring_zscores[i] is not None:
            patient_data[scoring + '_measures'] = pd.concat([scoring_ranks[i].loc[:, 'rank_' + patient],
                                                            scoring_zscores[i].loc[:, 'zscore_' + patient],
                                                            scoring_occurrences[i]], axis=1)
        else:
            patient_data[scoring + '_measures'] = pd.concat([scoring_ranks[i].loc[:, 'rank_' + patient],
                                                            scoring_occurrences[i]], axis=1)

        if scoring != 'Batch Phospho':
            patient_data[scoring + '_significance'] = scoring_dfs[i]['significance'].loc[:, patient].rename('Significance')

    return patient_data


def create_fp_worksheet(sheet_name: str,
                        fp: pd.DataFrame,
                        measures: Dict[str, Dict],
                        writer: pd.ExcelWriter,
                        fp_annotation_columns: Dict[str, str]) -> None:
    """
    Describe
    :param sheet_name:
    :param fp: patients intensities plus metadata and baskets annot
    :param df: measures fc, rank, z-score etc
    :param writer:
    :param fp_annotation_columns:

    """
    df = measures['fp']

    annotations = fp[fp_annotation_columns.keys()]
    annotations = annotations.reindex(fp_annotation_columns.keys(), axis=1)
    annotations = annotations.rename(fp_annotation_columns, axis='columns')

    df = pd.concat([df, annotations], axis=1)

    # Get the xlsxwriter workbook and worksheet objects
    worksheet, workbook = create_workbook(df, writer, sheet_name)

    # Add cell formats
    format_no_dec = workbook.add_format({'num_format': '#,##0'})
    format_two_dec = workbook.add_format({'num_format': '#,##0.00'})
    format_p_value = workbook.add_format({'num_format': "0.00E+00"})
    worksheet.set_column('A:A', 15)                 # gene name
    worksheet.set_column('B:C', 12, format_no_dec)  # rank and occurrence
    worksheet.set_column('D:E', 12, format_two_dec) # fold change and z-score
    worksheet.set_column('F:F', 12, format_p_value) # p-value
    worksheet.set_column('G:G', 25)                 # ident metadata num of peptides
    worksheet.set_column('H:H', 12, format_two_dec) # intensity
    worksheet.set_column('I:J', 15)                 # topas annot and poi annot


def create_pp_worksheet(sheet_name: str,
                        pp: pd.DataFrame,
                        measures: Dict[str, Dict],
                        writer: pd.ExcelWriter,
                        pp_annotation_columns: Dict[str, str]) -> None:

    df = measures['pp']
    phospho_in_batch = measures['Batch Phospho_measures']
    annotations = pp[pp_annotation_columns.keys()]
    annotations = annotations.reindex(pp_annotation_columns.keys(), axis=1)
    annotations = annotations.rename(pp_annotation_columns, axis='columns')

    phospho_in_batch = phospho_in_batch.loc[:, phospho_in_batch.columns.str.contains('rank')]
    phospho_in_batch.columns = ['Batch Rank']

    df = pd.concat([df, phospho_in_batch, annotations], axis=1)
    df = df.reset_index().set_index('Modified sequence')

    # move Gene names and Proteins annot to start of df
    locations, col_names = [0, 10], ['Gene names', 'Proteins']
    df = move_columns_to_start(df, locations, col_names)

    # Get the xlsxwriter workbook and worksheet objects
    worksheet, workbook = create_workbook(df, writer, sheet_name)

    # Add cell formats
    format_no_dec = workbook.add_format({'num_format': '#,##0'})
    format_two_dec = workbook.add_format({'num_format': '#,##0.00'})
    format_p_value = workbook.add_format({'num_format': "0.00E+00"})
    worksheet.set_column('A:A', 22)                 # modified sequence
    worksheet.set_column('B:B', 15)                 # gene names
    worksheet.set_column('C:D', 15, format_no_dec)  # Rank and occurrence
    worksheet.set_column('E:F', 12, format_two_dec) # Fold change and z-score
    worksheet.set_column('G:G', 12, format_p_value) # p-value
    worksheet.set_column('H:H', 12, format_no_dec)  # Z-score rank inside batch
    worksheet.set_column('I:I', 12, format_two_dec) # intensity
    worksheet.set_column('J:J', 25)                 # ident metadata imputed
    worksheet.set_column('K:M', 13)                 # topas annot, protein names, topas sub annot, poi annot # TODO: reorder
    worksheet.set_column('N:X', 13)                 # PSP annotations
    # worksheet.set_column('Y:Y', 20)               # PSP URL


def create_wp2_worksheet(sheet_name: str,
                         dfs: Dict[str, pd.DataFrame],
                         writer: pd.ExcelWriter,
                         extra_annotation_columns: Dict[str, str],
                         basket_annot_dict,
                         basket_subset=None) -> None:
    valid_columns = list(set(extra_annotation_columns.keys()).intersection(dfs[f"{sheet_name}_measures"].columns))
    measures = dfs[sheet_name + '_measures'][valid_columns]
    valid_batch_columns = list(set(extra_annotation_columns.keys()).intersection(dfs['Batch ' + sheet_name + '_measures'].columns))
    batch_measures = dfs['Batch ' + sheet_name + '_measures'][valid_batch_columns]
    significance_score = dfs[sheet_name + '_significance']
    if sheet_name == 'Substrate phosphorylation score':
        significance_score = significance_score.reset_index(level='No. of total targets', drop=True)

    if basket_annot_dict is not None:
        index_values = 'Gene names'
        for i, score_type in enumerate(['POI', 'TOPAS_score']):
        # for i, score_type in enumerate(['POI']):
            # use dictionary to assign basket annotation - NB! has to be dataframe
            if sheet_name == 'Substrate phosphorylation score':
                index_values = 'PSP Kinases'

            basket_df = measures.index.get_level_values(index_values).to_frame()



            # if sheet_name == 'Substrate phosphorylation score':
            #     annot_dict = basket_annot_dict['fp']

            if score_type == 'POI':
                annot_dict = basket_annot_dict['poi']
                # annot_dict = clinical_tools.read_clinical_annotation(annot_files, 'fp', 'POI') # fp not used if annot type == poi
            else:
                annot_dict = basket_annot_dict['fp']

            basket_df[score_type] = basket_df.apply(
                clinical_tools.map_identifier_list_to_annot_types, annot_dict=annot_dict,
                annot_type=score_type, with_weights=False, axis=1)

            basket_df.index = measures.index
            if sheet_name == 'Substrate phosphorylation score':
                basket_df = basket_df.drop(['PSP Kinases'], axis=1)
            else:
                basket_df = basket_df.drop('Gene names', axis=1)
            measures = pd.merge(left=measures, right=basket_df, on=index_values)
        for basket_type in ['POI', 'TOPAS_score']:
            # remove duplicated basket annotation
            measures[basket_type] = measures[basket_type].apply(clinical_process.get_unique_baskets)


    # rename the metric columns and baskets
    measures = measures.rename(extra_annotation_columns, axis='columns')
    
    # measures = measures.rename({'basket': 'Basket', 'sub_basket': 'Subbasket'}, axis='columns')
    batch_measures = batch_measures.rename(extra_annotation_columns, axis='columns') \
        .add_prefix('Batch ')

    if sheet_name == 'Protein score':
        wp2_score = dfs[sheet_name]
        sheet_name = 'Protein' + ' phosphorylation score'
        df_subset = ['Score', 'Rank', 'Occurrence', 'Z-score', 'Significance', 'TOPAS annot', 'POI category',  'Batch Rank', 'Batch Occurrence']
    else:
        wp2_score = dfs[sheet_name].reset_index(level='No. of total targets')
        batch_measures = batch_measures.reset_index(level='No. of total targets')
        batch_measures = batch_measures.drop('No. of total targets', axis=1)
        df_subset = ['No. of total targets', 'Score', 'Targets', 'Rank', 'Occurrence', 'Z-score', 'Significance',
                     'TOPAS annot', 'POI category', 'Batch Rank', 'Batch Occurrence']
        wp2_score.columns = ['No. of total targets', 'Score', 'Targets']  # is this needed?
    if isinstance(wp2_score, pd.Series):
        wp2_score = wp2_score.to_frame(name='Score')  # Convert Series to DataFrame with column name

    df = pd.concat([wp2_score, measures, significance_score, batch_measures], axis=1)
    df.index.name = 'Kinase' if sheet_name == 'Substrate phosphorylation score' else 'Protein'
    if basket_annot_dict is not None:
        df = df[df_subset]
    
    # Get the xlsxwriter workbook and worksheet objects
    worksheet, workbook = create_workbook(df, writer, sheet_name)

    # Add cell formats
    format_no_dec = workbook.add_format({'num_format': '#,##0'})
    format_two_dec = workbook.add_format({'num_format': '#,##0.00'})

    if sheet_name == 'Substrate phosphorylation score':
        worksheet.set_column('A:A', 20)  # Kinase
        worksheet.set_column('B:B', 20, format_no_dec)  # targets of cohort
        worksheet.set_column('C:C', 14, format_two_dec) # score
        worksheet.set_column('D:F', 12, format_no_dec)  # targets in sample + rank + occurrence
        worksheet.set_column('G:G', 14, format_two_dec) # z-score
        worksheet.set_column('H:H', 15, format_no_dec)  # significance
        worksheet.set_column('I:J', 15, format_no_dec)  # topas annot+poi annot
        worksheet.set_column('K:L', 17, format_no_dec)  # rank+occurrence in batch

    if sheet_name == 'Protein phosphorylation score':
        worksheet.set_column('A:A', 20)  # Protein
        worksheet.set_column('B:B', 16, format_two_dec) # score
        worksheet.set_column('C:D', 12, format_no_dec)  # rank + occurrence
        worksheet.set_column('E:E', 14, format_two_dec) # z-score
        worksheet.set_column('F:F', 15, format_no_dec)  # significance
        worksheet.set_column('G:H', 15, format_no_dec)  # topas annot+poi annot
        worksheet.set_column('I:J', 17, format_no_dec)  # rank+occurrence in batch


def create_score_worksheet(sheet_name: str,
                            dfs: Dict[str, pd.DataFrame],
                            writer: pd.ExcelWriter,
                            basket_column: str,
                            extra_annotation_columns: Dict[str, str],
                            basket_subset=None) -> None:
    valid_columns = list(set(extra_annotation_columns.keys()).intersection(dfs[f"{sheet_name}_measures"].columns))
    measures = dfs[sheet_name + '_measures'][valid_columns]
    valid_batch_columns = list(set(extra_annotation_columns.keys()).intersection(dfs['Batch ' + sheet_name + '_measures'].columns))
    batch_measures = dfs['Batch ' + sheet_name + '_measures'][valid_batch_columns]
    significance_score = dfs[sheet_name + '_significance']

    # rename the metric columns
    measures = measures.rename(extra_annotation_columns, axis='columns')
    batch_measures = batch_measures.rename(extra_annotation_columns, axis='columns') \
        .add_prefix('Batch ')  #.drop('Batch_Z-score', axis=1)
    # Prepare score df by splitting basket name into basket, subbasket and level of score
    if sheet_name == 'TOPAS subscores':
        dfs[sheet_name] = pd.DataFrame({'Kinase': dfs[sheet_name].index.to_series().apply(lambda x: x.split(' - ')[0]),
                                        'TOPAS score level': dfs[sheet_name].index.to_series().apply(lambda x: x.split(' - ')[1]),
                                        'Data level': dfs[sheet_name].index.to_series().apply(lambda x: x.split(' - ')[2]),
                                        'Score': dfs[sheet_name].values})
        data_to_concatenate = [dfs[sheet_name], measures, significance_score, batch_measures]
    else:
        dfs[sheet_name] = dfs[sheet_name].to_frame(name='Score')
        data_to_concatenate = [dfs[sheet_name], measures, significance_score, batch_measures]
        
    # combine with patient data
    df = pd.concat(data_to_concatenate, axis=1)

    df.index.name = 'Kinase'
    use_index = True
    if sheet_name == 'TOPAS subscores':
        use_index = False

    # Get the xlsxwriter workbook and worksheet objects
    worksheet, workbook = create_workbook(df, writer, sheet_name, use_index)

    # Add cell formats
    format_no_dec = workbook.add_format({'num_format': '#,##0'})
    format_two_dec = workbook.add_format({'num_format': '#,##0.00'})
    if basket_column == 'TOPAS scores':
        worksheet.set_column('A:A', 20)                 # topas kinase
        worksheet.set_column('B:B', 15, format_two_dec) # topas score
        worksheet.set_column('C:C', 12, format_no_dec)  # rank
        worksheet.set_column('D:D', 12, format_two_dec) # z-score
        worksheet.set_column('E:E', 15, format_no_dec)  # occurrence
        worksheet.set_column('F:H', 15, format_no_dec)  # significance+zscore rank in batch+occurrence in batch
        worksheet.set_column('I:M', 22, format_no_dec)  # no. sign scores in topas subscores
    else:
        worksheet.set_column('A:B', 20)                 # basket + subbasket
        worksheet.set_column('C:C', 25)                 # level
        worksheet.set_column('D:D', 15, format_two_dec) # topas subscore
        worksheet.set_column('E:E', 12, format_no_dec)  # rank
        worksheet.set_column('F:F', 12, format_two_dec) # z-score
        worksheet.set_column('G:H', 15, format_no_dec)  # occurrence+significance
        worksheet.set_column('I:J', 15, format_no_dec)  # rank in batch+occurrence in batch


def create_workbook(patient_data, writer, sheet_name, use_index: bool = True):
    patient_data.to_excel(writer, sheet_name=sheet_name, index=use_index)  # this is the slow part...
    workbook, worksheet = writer.book, writer.sheets[sheet_name]
    return worksheet, workbook


def move_columns_to_start(df, locations, col_names):
    df_new = df.drop(labels=col_names, axis=1)
    for location, col_name in zip(locations, col_names):
        df_new.insert(location, col_name, df[col_name])
    df = df_new
    return df


def assign_significance_score(col: pd.Series):
    score_percentage_thresholds = [0.05, 0.10, 0.20, 0.90]
    sorted_col = col.sort_values(ascending=False)
    for i, threshold in enumerate(score_percentage_thresholds):
        previous_threshold_percentage = math.ceil(col.size * score_percentage_thresholds[i - 1])
        top_threshold_percentage = math.ceil(col.size * threshold)
        if i == 0:
            col.loc[sorted_col.iloc[:top_threshold_percentage].index] = i + 1
        if i == 3:
            col.loc[sorted_col.iloc[top_threshold_percentage:].index] = i + 1
            col.loc[sorted_col.iloc[previous_threshold_percentage:top_threshold_percentage].index] = np.nan
        else:
            col.loc[sorted_col.iloc[previous_threshold_percentage:top_threshold_percentage].index] = i + 1
    return col


if __name__ == '__main__':
    import argparse

    from . import config

    parser = argparse.ArgumentParser()
    parser.add_argument("-c", "--config", required=True,
                        help="Absolute path to configuration file.")
    args = parser.parse_args(sys.argv[1:])

    configs = config.load(args.config)

    create_report(configs["results_folder"], configs["preprocessing"]["debug"], **configs["report"],
                  data_types=configs["data_types"])
